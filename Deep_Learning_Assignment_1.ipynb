{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "az-dxaC5bFmQ",
        "outputId": "b6de0010-80c3-4bc3-bb51-17291b826620"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17464789/17464789 [==============================] - 1s 0us/step\n",
            "Epoch 1/5\n",
            "157/157 [==============================] - 112s 700ms/step - loss: 0.6212 - accuracy: 0.6296 - val_loss: 0.5254 - val_accuracy: 0.7510\n",
            "Epoch 2/5\n",
            "157/157 [==============================] - 113s 716ms/step - loss: 0.4368 - accuracy: 0.8051 - val_loss: 0.4801 - val_accuracy: 0.7702\n",
            "Epoch 3/5\n",
            "157/157 [==============================] - 115s 734ms/step - loss: 0.3619 - accuracy: 0.8463 - val_loss: 0.4634 - val_accuracy: 0.7944\n",
            "Epoch 4/5\n",
            "157/157 [==============================] - 114s 724ms/step - loss: 0.3712 - accuracy: 0.8387 - val_loss: 0.4589 - val_accuracy: 0.7948\n",
            "Epoch 5/5\n",
            "157/157 [==============================] - 111s 708ms/step - loss: 0.3178 - accuracy: 0.8709 - val_loss: 0.5122 - val_accuracy: 0.7680\n",
            "175/196 [=========================>....] - ETA: 3s - loss: 0.5077 - accuracy: 0.7676"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN, GRU, LSTM, Dense\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "\n",
        "# Set the maximum number of words to consider in the reviews\n",
        "max_words = 5000\n",
        "\n",
        "# Load the IMDB dataset\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_words)\n",
        "\n",
        "# Pad the sequences to have the same length\n",
        "max_length = 500\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=max_length)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=max_length)\n",
        "\n",
        "# Lists to store accuracy for each model\n",
        "accuracies = []\n",
        "\n",
        "# Models to compare\n",
        "model_names = [\"RNN\", \"GRU\", \"LSTM\"]\n",
        "\n",
        "models = [\n",
        "    Sequential([\n",
        "        Embedding(max_words, 100, input_length=max_length),\n",
        "        SimpleRNN(128),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ]),\n",
        "    Sequential([\n",
        "        Embedding(max_words, 100, input_length=max_length),\n",
        "        GRU(128),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ]),\n",
        "    Sequential([\n",
        "        Embedding(max_words, 100, input_length=max_length),\n",
        "        LSTM(128),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "]\n",
        "\n",
        "# Compile and train models\n",
        "batch_size = 128\n",
        "epochs = 5\n",
        "\n",
        "# Lists to store history for each model\n",
        "histories = []\n",
        "\n",
        "for model in models:\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.2)\n",
        "    histories.append(history)\n",
        "    _, accuracy = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
        "    accuracies.append(accuracy)\n",
        "\n",
        "# Create a line plot for accuracy over epochs\n",
        "plt.figure(figsize=(10, 6))\n",
        "for i, history in enumerate(histories):\n",
        "    plt.plot(history.history['accuracy'], label=model_names[i])\n",
        "\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Comparison of Recurrent Models for Sentiment Analysis')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Zdw5AEDBp7p8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}